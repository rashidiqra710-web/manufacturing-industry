# -*- coding: utf-8 -*-
"""Computer vision defect detection (e.g., textile de

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/#fileId=https%3A//storage.googleapis.com/kaggle-colab-exported-notebooks/iqra0rashid/computer-vision-defect-detection-e-g-textile-de.623e0a76-e2a4-49db-aa69-6885c4bcdf13.ipynb%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com/20251020/auto/storage/goog4_request%26X-Goog-Date%3D20251020T041107Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D43c2585df82a18b73827aeecd1d6e79fc7d92ba6ff1cd76cdca82192a53172a916e98fe345b484e29dc705ca7dfe21c61e385e9ae84b994d5456ef83793698eafcbb7ef014f8d3a93a443e17bdb47a857671e1fff8e2b4a24ea1cb8762168acbbf6abd6acd3f2d54c57796bb9a2fa73fe3fc7384acf94c707051114f7234cd6b0dc936a1ff13361adb080e4beec06f37c09e5c939f193098f4ac3563e42f5ab0fa409a28709bf46efdfdc1fa760d37ebdd18611ab69db3049078c538bb7189ff5ff229f54f011830b516656948af9e478916c40706165d5870867f09e36726ef5f4a9584e18742404575eee8ce7a633ea729e7da198dcbcfd3a3458acca17869
"""

# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,
# THEN FEEL FREE TO DELETE THIS CELL.
# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON
# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR
# NOTEBOOK.
import kagglehub
nexuswho_fabric_defects_dataset_path = kagglehub.dataset_download('nexuswho/fabric-defects-dataset')
ziya07_multi_class_fabric_defect_detection_dataset_path = kagglehub.dataset_download('ziya07/multi-class-fabric-defect-detection-dataset')

print('Data source import complete.')

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, BatchNormalization
from tensorflow.keras.optimizers import Adam, AdamW  # <-- Fixed here
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import numpy as np
import matplotlib.pyplot as plt
from sklearn.utils.class_weight import compute_class_weight
import os
import shutil
from sklearn.model_selection import train_test_split

import os
import shutil

# Source dataset paths
ds1 = "/kaggle/input/fabric-defects-dataset/Fabric Defects Dataset/Fabric Defect Dataset"
ds2 = "/kaggle/input/multi-class-fabric-defect-detection-dataset/Dataset"

# Destination merged dataset
merged_base = "/kaggle/working/fabric_defects_merged_all"

# Remove existing destination folder if it exists
if os.path.exists(merged_base):
    shutil.rmtree(merged_base)

# Create target folders
defected_path = os.path.join(merged_base, "defected")
defect_free_path = os.path.join(merged_base, "defect_free")

os.makedirs(defected_path, exist_ok=True)
os.makedirs(defect_free_path, exist_ok=True)

# Classes to map
defect_free_classes = ["defect free","defect free"]
# All other folders are defected (including Vertical)
# but we can define explicitly for clarity:
defected_classes_ds1 = ["Vertical", "horizontal", "hole", "lines", "stain"]
defected_classes_ds2 = ["Broken stitch", "Needle mark", "Pinched fabric",
                         "Vertical", "hole", "horizontal", "lines", "stain"]

def copy_images(source_dir, defected_classes, defect_free_classes):
    """
    Copies images from source_dir into defected and defect_free folders
    """
    for cls in os.listdir(source_dir):
        cls_path = os.path.join(source_dir, cls)
        if not os.path.isdir(cls_path):
            continue  # skip non-folder files if any

        # Decide destination
        if cls in defect_free_classes:
            dst_dir = defect_free_path
        else:
            dst_dir = defected_path

        # Copy images
        for fname in os.listdir(cls_path):
            src = os.path.join(cls_path, fname)
            dst = os.path.join(dst_dir, f"{cls}_{fname}")
            # Add class name prefix to avoid duplicate file names
            shutil.copy(src, dst)

# Copy from both datasets
copy_images(ds1, defected_classes_ds1, defect_free_classes)
copy_images(ds2, defected_classes_ds2, defect_free_classes)

print("✅ Both datasets merged into two categories: defected & defect_free")

# Show image counts
print("\nImage counts after merging:")
print("Defected:", len(os.listdir(defected_path)))
print("Defect_free:", len(os.listdir(defect_free_path)))

import os
import shutil
from sklearn.model_selection import train_test_split

# Paths
src_base = "/kaggle/working/fabric_defects_merged_all"
dst_base = "/kaggle/working/fabric_defects_split"

# Remove old split folder if exists
if os.path.exists(dst_base):
    shutil.rmtree(dst_base)

# Create directories for train/val/test
splits = ["train", "val", "test"]
for split in splits:
    os.makedirs(os.path.join(dst_base, split, "defected"), exist_ok=True)
    os.makedirs(os.path.join(dst_base, split, "defect_free"), exist_ok=True)

# Function to split and copy files
def split_and_copy(class_name):
    class_dir = os.path.join(src_base, class_name)
    files = os.listdir(class_dir)

    # Shuffle and split
    train_files, temp_files = train_test_split(files, test_size=0.2, random_state=42)  # 80% train
    val_files, test_files = train_test_split(temp_files, test_size=0.5, random_state=42)  # 10% val, 10% test

    # Copy files
    for f in train_files:
        shutil.copy(os.path.join(class_dir, f), os.path.join(dst_base, "train", class_name, f))

    for f in val_files:
        shutil.copy(os.path.join(class_dir, f), os.path.join(dst_base, "val", class_name, f))

    for f in test_files:
        shutil.copy(os.path.join(class_dir, f), os.path.join(dst_base, "test", class_name, f))

    return len(train_files), len(val_files), len(test_files)

# Split each class
counts = {}
for cls in ["defected", "defect_free"]:
    counts[cls] = split_and_copy(cls)

print("✅ Dataset split into Train/Val/Test (80:10:10)")

# Show counts
print("\nImage distribution:")
for cls, (train_c, val_c, test_c) in counts.items():
    print(f"{cls}:  Train={train_c},  Val={val_c},  Test={test_c}")

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
from torchvision import transforms, datasets
from transformers import ViTModel, ViTConfig
import numpy as np
from sklearn.utils.class_weight import compute_class_weight
from sklearn.metrics import f1_score, classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
import os
from PIL import Image

# ================== Configuration ==================
IMG_SIZE = (224, 224)
BATCH_SIZE = 32
EPOCHS = 10
DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# ================== Data Transforms ==================
train_transform = transforms.Compose([
    transforms.Resize(IMG_SIZE),
    transforms.RandomRotation(40),
    transforms.RandomHorizontalFlip(0.3),
    transforms.RandomVerticalFlip(0.3),
    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

val_test_transform = transforms.Compose([
    transforms.Resize(IMG_SIZE),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# ================== Datasets ==================
train_dataset = datasets.ImageFolder(
    root='/kaggle/working/fabric_defects_split/train',
    transform=train_transform
)

val_dataset = datasets.ImageFolder(
    root='/kaggle/working/fabric_defects_split/val',
    transform=val_test_transform
)

test_dataset = datasets.ImageFolder(
    root='/kaggle/working/fabric_defects_split/test',  # Assuming you have a test directory
    transform=val_test_transform
)

# ================== Data Loaders ==================
train_loader = DataLoader(
    train_dataset,
    batch_size=BATCH_SIZE,
    shuffle=True,
    num_workers=2
)

val_loader = DataLoader(
    val_dataset,
    batch_size=BATCH_SIZE,
    shuffle=False,
    num_workers=2
)

test_loader = DataLoader(
    test_dataset,
    batch_size=BATCH_SIZE,
    shuffle=False,
    num_workers=2
)

# ================== Model Definition ==================
class ViTClassifier(nn.Module):
    def __init__(self, num_classes=1):
        super(ViTClassifier, self).__init__()
        self.vit = ViTModel.from_pretrained("google/vit-base-patch16-224-in21k")

        # Freeze ViT parameters if desired
        for param in self.vit.parameters():
            param.requires_grad = False

        self.classifier = nn.Sequential(
            nn.Linear(768, 512),
            nn.ReLU(),
            nn.BatchNorm1d(512),
            nn.Dropout(0.5),
            nn.Linear(512, 256),
            nn.ReLU(),
            nn.BatchNorm1d(256),
            nn.Dropout(0.5),
            nn.Linear(256, num_classes),
            nn.Sigmoid() if num_classes == 1 else nn.Softmax(dim=1)
        )

    def forward(self, x):
        outputs = self.vit(x)
        cls_token = outputs.last_hidden_state[:, 0]  # CLS token
        return self.classifier(cls_token)

# ================== Model Initialization ==================
model = ViTClassifier(num_classes=1).to(DEVICE)

# ================== Optimizer and Loss ==================
optimizer = optim.AdamW(
    model.parameters(),
    lr=5e-5,
    weight_decay=1e-5
)

criterion = nn.BCELoss()

# ================== Class Weights ==================
train_targets = []
for _, labels in train_loader:
    train_targets.extend(labels.numpy())
train_targets = np.array(train_targets)

class_weights = compute_class_weight(
    class_weight='balanced',
    classes=np.unique(train_targets),
    y=train_targets
)
class_weights = torch.tensor(class_weights, dtype=torch.float32).to(DEVICE)
print("Class Weights:", class_weights.cpu().numpy())

# ================== Training Metrics ==================
def calculate_metrics(outputs, targets):
    outputs = outputs.cpu().detach().numpy()
    targets = targets.cpu().numpy()

    preds = (outputs > 0.5).astype(int)

    accuracy = np.mean(preds == targets)
    precision = np.sum((preds == 1) & (targets == 1)) / (np.sum(preds == 1) + 1e-8)
    recall = np.sum((preds == 1) & (targets == 1)) / (np.sum(targets == 1) + 1e-8)

    return accuracy, precision, recall

# ================== Training Loop ==================
def train_model(model, train_loader, val_loader, optimizer, criterion, epochs, class_weights, device):
    train_losses = []
    val_losses = []
    train_accuracies = []
    val_accuracies = []
    train_precisions = []
    val_precisions = []
    train_recalls = []
    val_recalls = []

    best_val_loss = float('inf')

    for epoch in range(epochs):
        # Training phase
        model.train()
        train_loss = 0.0
        train_acc = 0.0
        train_precision = 0.0
        train_recall = 0.0

        for batch_idx, (data, targets) in enumerate(train_loader):
            data, targets = data.to(device), targets.to(device).float().unsqueeze(1)

            optimizer.zero_grad()
            outputs = model(data)
            loss = criterion(outputs, targets)

            # Apply class weights
            weights = class_weights[targets.long().squeeze()]
            loss = (loss * weights).mean()

            loss.backward()
            optimizer.step()

            train_loss += loss.item()
            acc, prec, rec = calculate_metrics(outputs, targets)
            train_acc += acc
            train_precision += prec
            train_recall += rec

        # Validation phase
        model.eval()
        val_loss = 0.0
        val_acc = 0.0
        val_precision = 0.0
        val_recall = 0.0

        with torch.no_grad():
            for data, targets in val_loader:
                data, targets = data.to(device), targets.to(device).float().unsqueeze(1)
                outputs = model(data)
                loss = criterion(outputs, targets)

                val_loss += loss.item()
                acc, prec, rec = calculate_metrics(outputs, targets)
                val_acc += acc
                val_precision += prec
                val_recall += rec

        # Calculate averages
        train_loss /= len(train_loader)
        train_acc /= len(train_loader)
        train_precision /= len(train_loader)
        train_recall /= len(train_loader)

        val_loss /= len(val_loader)
        val_acc /= len(val_loader)
        val_precision /= len(val_loader)
        val_recall /= len(val_loader)

        # Store metrics
        train_losses.append(train_loss)
        val_losses.append(val_loss)
        train_accuracies.append(train_acc)
        val_accuracies.append(val_acc)
        train_precisions.append(train_precision)
        val_precisions.append(val_precision)
        train_recalls.append(train_recall)
        val_recalls.append(val_recall)

        print(f'Epoch {epoch+1}/{epochs}:')
        print(f'  Train Loss: {train_loss:.4f}, Acc: {train_acc:.4f}, Prec: {train_precision:.4f}, Rec: {train_recall:.4f}')
        print(f'  Val Loss: {val_loss:.4f}, Acc: {val_acc:.4f}, Prec: {val_precision:.4f}, Rec: {val_recall:.4f}')

        # Save best model
        if val_loss < best_val_loss:
            best_val_loss = val_loss
            torch.save(model.state_dict(), '/kaggle/working/best_model_vit_b16.pth')
            print('  Saved best model!')

    history = {
        'train_loss': train_losses,
        'val_loss': val_losses,
        'train_accuracy': train_accuracies,
        'val_accuracy': val_accuracies,
        'train_precision': train_precisions,
        'val_precision': val_precisions,
        'train_recall': train_recalls,
        'val_recall': val_recalls
    }

    return history

# ================== Start Training ==================
print("Starting training...")
history = train_model(
    model, train_loader, val_loader, optimizer, criterion,
    EPOCHS, class_weights, DEVICE
)

# ================== Plotting Function ==================
def plot_training_curves(history):
    epochs_range = range(len(history['train_loss']))

    plt.figure(figsize=(16, 10))

    plt.subplot(2, 2, 1)
    plt.plot(epochs_range, history['train_accuracy'], label='Train Accuracy')
    plt.plot(epochs_range, history['val_accuracy'], label='Val Accuracy')
    plt.legend()
    plt.title('Accuracy')

    plt.subplot(2, 2, 2)
    plt.plot(epochs_range, history['train_loss'], label='Train Loss')
    plt.plot(epochs_range, history['val_loss'], label='Val Loss')
    plt.legend()
    plt.title('Loss')

    plt.tight_layout()
    plt.show()

# Plot training curves
plot_training_curves(history)

# ================== Evaluation ==================
def evaluate_model(model, test_loader, device):
    model.eval()
    test_loss = 0.0
    all_preds = []
    all_targets = []

    with torch.no_grad():
        for data, targets in test_loader:
            data, targets = data.to(device), targets.to(device).float().unsqueeze(1)
            outputs = model(data)
            loss = criterion(outputs, targets)

            test_loss += loss.item()

            preds = (outputs.cpu().numpy() > 0.5).astype(int)
            all_preds.extend(preds.flatten())
            all_targets.extend(targets.cpu().numpy().flatten())

    test_loss /= len(test_loader)
    accuracy = np.mean(np.array(all_preds) == np.array(all_targets))

    return test_loss, accuracy, np.array(all_preds), np.array(all_targets)

# Load best model for evaluation
model.load_state_dict(torch.load('/kaggle/working/best_model_vit_b16.pth'))
test_loss, test_accuracy, y_pred, y_true = evaluate_model(model, test_loader, DEVICE)

print(f"\nTest Loss: {test_loss:.4f}")
print(f"Test Accuracy: {test_accuracy:.2%}")

# Calculate additional metrics
precision = np.sum((y_pred == 1) & (y_true == 1)) / (np.sum(y_pred == 1) + 1e-8)
recall = np.sum((y_pred == 1) & (y_true == 1)) / (np.sum(y_true == 1) + 1e-8)
f1 = f1_score(y_true, y_pred, average='weighted')

print(f"Test Precision: {precision:.2%}")
print(f"Test Recall: {recall:.2%}")
print(f"Test F1-Score (Weighted): {f1:.2%}")

# Classification Report
print("\nClassification Report:")
print(classification_report(y_true, y_pred, target_names=test_dataset.classes))

# Confusion Matrix
cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
            xticklabels=test_dataset.classes, yticklabels=test_dataset.classes)
plt.xlabel("Predicted Labels")
plt.ylabel("True Labels")
plt.title("Confusion Matrix")
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import torch
import numpy as np
from torchvision.utils import make_grid

def denormalize(tensor, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]):
    """Denormalize a tensor image for visualization"""
    tensor = tensor.clone()
    for t, m, s in zip(tensor, mean, std):
        t.mul_(s).add_(m)
    return tensor

def visualize_predictions(model, test_loader, device, num_samples=10):
    """
    Visualize predicted vs actual images
    """
    model.eval()

    # Get one batch of test data
    data_iter = iter(test_loader)
    images, labels = next(data_iter)

    # Move to device and get predictions
    images = images.to(device)
    labels = labels.to(device)

    with torch.no_grad():
        outputs = model(images)
        predictions = (outputs > 0.5).float().squeeze()

    # Convert to numpy for plotting
    images = images.cpu()
    labels = labels.cpu().numpy()
    predictions = predictions.cpu().numpy()

    # Denormalize images
    images = denormalize(images)

    # Get class names
    class_names = test_loader.dataset.classes

    # Create figure
    fig, axes = plt.subplots(2, 5, figsize=(20, 8))
    axes = axes.ravel()

    for i in range(num_samples):
        if i >= len(images):
            break

        # Get image, actual and predicted labels
        img = images[i].permute(1, 2, 0)  # CHW to HWC
        actual = labels[i]
        predicted = predictions[i]

        # Convert to class names
        actual_class = class_names[int(actual)]
        predicted_class = class_names[int(predicted)]

        # Plot image
        axes[i].imshow(img)
        axes[i].axis('off')

        # Set title with color coding
        color = 'green' if actual == predicted else 'red'
        axes[i].set_title(f'Actual: {actual_class}\nPredicted: {predicted_class}',
                         color=color, fontsize=12, fontweight='bold')

    plt.tight_layout()
    plt.show()

    return images, labels, predictions

# Alternative function that shows more detailed information including confidence scores
def visualize_predictions_detailed(model, test_loader, device, num_samples=10):
    """
    Visualize predictions with confidence scores and more details
    """
    model.eval()

    # Get data
    data_iter = iter(test_loader)
    images, labels = next(data_iter)

    # Move to device and get predictions
    images = images.to(device)
    labels = labels.to(device)

    with torch.no_grad():
        outputs = model(images)
        probabilities = outputs.squeeze().cpu().numpy()
        predictions = (outputs > 0.5).float().squeeze().cpu().numpy()

    images = images.cpu()
    labels = labels.cpu().numpy()

    # Denormalize images
    images = denormalize(images)

    # Get class names
    class_names = test_loader.dataset.classes

    # Create figure
    fig, axes = plt.subplots(2, 5, figsize=(22, 10))
    axes = axes.ravel()

    for i in range(num_samples):
        if i >= len(images):
            break

        img = images[i].permute(1, 2, 0)
        actual = labels[i]
        predicted = predictions[i]
        prob = probabilities[i]

        actual_class = class_names[int(actual)]
        predicted_class = class_names[int(predicted)]

        # Plot image
        axes[i].imshow(img)
        axes[i].axis('off')

        # Determine color and confidence text
        color = 'green' if actual == predicted else 'red'
        confidence = prob if predicted == 1 else (1 - prob)

        title = f'Actual: {actual_class}\nPredicted: {predicted_class}\nConfidence: {confidence:.3f}'
        axes[i].set_title(title, color=color, fontsize=11, fontweight='bold')

    plt.tight_layout()
    plt.show()

# Function to visualize misclassified samples only
def visualize_misclassifications(model, test_loader, device, num_samples=10):
    """
    Visualize only misclassified samples
    """
    model.eval()

    misclassified_images = []
    misclassified_labels = []
    misclassified_predictions = []
    misclassified_probs = []

    # Collect misclassified samples
    with torch.no_grad():
        for images, labels in test_loader:
            images = images.to(device)
            labels = labels.to(device)

            outputs = model(images)
            predictions = (outputs > 0.5).float().squeeze()
            probabilities = outputs.squeeze().cpu().numpy()

            # Find misclassified samples
            misclassified_mask = (predictions != labels).cpu().numpy()

            if np.any(misclassified_mask):
                misclassified_indices = np.where(misclassified_mask)[0]

                for idx in misclassified_indices:
                    if len(misclassified_images) >= num_samples:
                        break

                    misclassified_images.append(images[idx].cpu())
                    misclassified_labels.append(labels[idx].cpu().item())
                    misclassified_predictions.append(predictions[idx].cpu().item())
                    misclassified_probs.append(probabilities[idx])

            if len(misclassified_images) >= num_samples:
                break

    if not misclassified_images:
        print("No misclassified samples found!")
        return

    # Denormalize images
    misclassified_images = [denormalize(img) for img in misclassified_images]

    # Get class names
    class_names = test_loader.dataset.classes

    # Create figure
    num_samples = min(num_samples, len(misclassified_images))
    rows = (num_samples + 4) // 5  # Ceiling division
    fig, axes = plt.subplots(rows, 5, figsize=(22, 4 * rows))

    if rows == 1:
        axes = axes.reshape(1, -1)

    for i in range(num_samples):
        row = i // 5
        col = i % 5

        img = misclassified_images[i].permute(1, 2, 0)
        actual = misclassified_labels[i]
        predicted = misclassified_predictions[i]
        prob = misclassified_probs[i]

        actual_class = class_names[int(actual)]
        predicted_class = class_names[int(predicted)]
        confidence = prob if predicted == 1 else (1 - prob)

        axes[row, col].imshow(img)
        axes[row, col].axis('off')

        title = f'Actual: {actual_class}\nPredicted: {predicted_class}\nConf: {confidence:.3f}'
        axes[row, col].set_title(title, color='red', fontsize=10, fontweight='bold')

    # Hide empty subplots
    for i in range(num_samples, rows * 5):
        row = i // 5
        col = i % 5
        axes[row, col].axis('off')

    plt.suptitle(f'Misclassified Samples ({num_samples} shown)', fontsize=16, fontweight='bold')
    plt.tight_layout()
    plt.show()

# Function to show sample grid from each class
def visualize_class_samples(test_loader, num_samples_per_class=5):
    """
    Visualize sample images from each class
    """
    dataset = test_loader.dataset
    class_names = dataset.classes

    # Collect samples for each class
    class_samples = {class_name: [] for class_name in class_names}

    for image, label in dataset:
        class_name = class_names[label]
        if len(class_samples[class_name]) < num_samples_per_class:
            class_samples[class_name].append((image, label))

        # Check if we have enough samples for all classes
        if all(len(samples) >= num_samples_per_class for samples in class_samples.values()):
            break

    # Create figure
    num_classes = len(class_names)
    fig, axes = plt.subplots(num_classes, num_samples_per_class,
                            figsize=(3 * num_samples_per_class, 3 * num_classes))

    if num_classes == 1:
        axes = axes.reshape(1, -1)

    for class_idx, class_name in enumerate(class_names):
        for sample_idx in range(num_samples_per_class):
            if sample_idx < len(class_samples[class_name]):
                image, label = class_samples[class_name][sample_idx]
                image = denormalize(image).permute(1, 2, 0)

                if num_classes > 1:
                    axes[class_idx, sample_idx].imshow(image)
                    axes[class_idx, sample_idx].axis('off')
                    if sample_idx == 0:
                        axes[class_idx, sample_idx].set_ylabel(class_name,
                                                              rotation=0,
                                                              ha='right',
                                                              fontweight='bold')
                else:
                    axes[sample_idx].imshow(image)
                    axes[sample_idx].axis('off')
                    if sample_idx == 0:
                        axes[sample_idx].set_ylabel(class_name,
                                                  rotation=0,
                                                  ha='right',
                                                  fontweight='bold')

    plt.suptitle('Sample Images from Each Class', fontsize=16, fontweight='bold')
    plt.tight_layout()
    plt.show()

# ================== USAGE EXAMPLES ==================

# Load your best model first
model.load_state_dict(torch.load('/kaggle/working/best_model_vit_b16.pth'))

print("Visualizing 10 random predictions:")
# 1. Visualize random predictions
visualize_predictions(model, test_loader, DEVICE, num_samples=10)

print("\nVisualizing predictions with confidence scores:")
# 2. Visualize with confidence scores
visualize_predictions_detailed(model, test_loader, DEVICE, num_samples=10)

print("\nVisualizing misclassified samples:")
# 3. Visualize only misclassified samples
visualize_misclassifications(model, test_loader, DEVICE, num_samples=10)

print("\nVisualizing sample images from each class:")
# 4. Visualize sample images from each class
visualize_class_samples(test_loader, num_samples_per_class=5)

# Additional: Calculate and display accuracy statistics
def print_prediction_stats(model, test_loader, device):
    model.eval()

    all_predictions = []
    all_labels = []

    with torch.no_grad():
        for images, labels in test_loader:
            images = images.to(device)
            labels = labels.to(device)

            outputs = model(images)
            predictions = (outputs > 0.5).float().squeeze()

            all_predictions.extend(predictions.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

    all_predictions = np.array(all_predictions)
    all_labels = np.array(all_labels)

    accuracy = np.mean(all_predictions == all_labels)
    misclassified = np.sum(all_predictions != all_labels)
    total = len(all_labels)

    print(f"\n=== Prediction Statistics ===")
    print(f"Total samples: {total}")
    print(f"Correct predictions: {total - misclassified}")
    print(f"Misclassified: {misclassified}")
    print(f"Accuracy: {accuracy:.2%}")
    print(f"Error rate: {(misclassified/total):.2%}")

# Print statistics
print_prediction_stats(model, test_loader, DEVICE)